import com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar
import com.github.jengelman.gradle.plugins.shadow.transformers.AppendingTransformer

buildscript {
    dependencies {
        classpath "com.diffplug.spotless:spotless-plugin-gradle:3.4.0"
        classpath 'com.github.jengelman.gradle.plugins:shadow:1.2.4'
        // Rio Addon
        classpath 'com.apple.cie.rio:gradle-build-plugin:latest.release'
    }
}

// Used to promote a staging release build
// https://github.com/Codearte/gradle-nexus-staging-plugin
// gradle closeAndReleaseRepository
plugins
{
    id "io.codearte.nexus-staging" version "0.8.0"
}

apply from: 'dependencies.gradle'
apply plugin: 'java'
apply plugin: 'checkstyle'
apply plugin: 'maven'
apply plugin: 'signing'
apply plugin: "com.diffplug.gradle.spotless"
apply plugin: 'idea'
apply plugin: 'eclipse'
apply plugin: 'com.github.johnrengelman.shadow'

// Rio addon
apply plugin: 'rio-library'

sourceCompatibility=1.8
targetCompatibility=1.8

repositories
{
    // For geotools
    maven { url "http://download.osgeo.org/webdav/geotools/" }
    mavenCentral()
    // For Spark CDH
    maven { url "https://repository.cloudera.com/content/repositories/releases/" }
    // For jetty (through spark)
    maven { url "http://repository.cloudera.com/cloudera/cloudera-repos/" }
}

idea {
    project {
        languageLevel = '1.8'
    }
}

spotless {
   java {
      importOrder(['static java', 'static javax', 'static org', 'static com', 'static scala', 'java', 'javax', 'org', 'com', 'scala'])
      removeUnusedImports()
      eclipse().configFile 'config/format/code_format.xml'
   }
}

// corresponds to POM description
description = "Atlas Checks"

// This is to skip the tasks for which there is a skip<TaskName>=true environment variable
def skippedTaskNames = System.getenv().findAll { key, value ->
    key.startsWith("skip") && value.equalsIgnoreCase("true")
}.keySet().collect { it.substring(4) }

gradle.startParameter.excludedTaskNames += skippedTaskNames

checkstyle
{
    toolVersion = versions.checkstyle
}

sourceSets
{
    integrationTest
    {
        java
        {
            compileClasspath += main.output + test.output
            runtimeClasspath += main.output + test.output
            srcDir file('src/integrationTest/java')
        }
        resources.srcDir file('src/integrationTest/resources')
    }
}

test
{
    testLogging
    {
        events "passed", "skipped", "failed"
    }
}

configurations
{
    all
    {
        resolutionStrategy
        {
            force packages.atlas
            force packages.atlas_generator

            // Snappy 1.1.1.6 is the one that has the proper .so libs.
            // https://github.com/xerial/snappy-java/issues/6
            force 'org.xerial.snappy:snappy-java:1.1.1.6'
            force 'org.scala-lang:scala-library:2.10.2'

            // http://stackoverflow.com/questions/31039367/spark-parallelize-could-not-find-creator-property-with-name-id
            // This is to avoid a JsonMappingException for something named 'id' in org.apache.spark.rdd.RDDOperationScope
            force 'com.fasterxml.jackson.core:jackson-core:2.4.4'
            force 'com.fasterxml.jackson.core:jackson-databind:2.4.4'
            force 'org.slf4j:slf4j-api:1.7.12'
        }
    }
    shaded
    {
        // Hadoop and Spark are way too fat.
        exclude group: 'org.apache.hadoop'
        exclude group: 'org.apache.spark'
        exclude group: 'org.scala-lang'
    }
    runtime
    archives
    integrationTestCompile.extendsFrom testCompile
    integrationTestRuntime.extendsFrom testRuntime
}

dependencies
{
    compile packages.commons
    compile packages.atlas
    compile packages.atlas_generator
}

task integrationTest(type: Test) {
    testClassesDir = sourceSets.integrationTest.output.classesDir
    classpath = sourceSets.integrationTest.runtimeClasspath
    testLogging
    {
        events "passed", "skipped", "failed"
    }
}

check.dependsOn integrationTest
integrationTest.mustRunAfter test

tasks.withType(Test) {
    reports.html.destination = file("${reporting.baseDir}/${name}")
}

/**
 * Artifact related items
 */
// task javadocJar(type: Jar) {
//     classifier = 'javadoc'
//     from javadoc
// }
//
// task sourcesJar(type: Jar) {
//     classifier = 'sources'
//     from sourceSets.main.allSource
// }

task shaded(type: Jar) {
    baseName = project.name
    from {
        configurations.shaded.collect {
            it.isDirectory() ? it : zipTree(it).matching {
                exclude {
                    it.path.contains('META-INF') && (it.path.endsWith('.SF') || it.path.endsWith('.DSA') || it.path.endsWith('.RSA'))
                }
            }
        }
    }
    with jar
    zip64 = true
}

shadowJar {
    baseName = project.name
    mergeServiceFiles()
    transform(com.github.jengelman.gradle.plugins.shadow.transformers.AppendingTransformer) {
        resource = 'reference.conf'
    }
    zip64 = true
}

// artifacts
// {
//     archives javadocJar, sourcesJar
// }

/**
 * Deployment related items
 */
import org.gradle.plugins.signing.Sign

gradle.taskGraph.whenReady { taskGraph ->
    if (taskGraph.allTasks.any { it instanceof Sign }) {
        allprojects { ext."signing.keyId" = System.getenv('GPG_KEY_ID') }
        allprojects { ext."signing.secretKeyRingFile" = System.getenv('GPG_KEY_LOCATION') }
        allprojects { ext."signing.password" = System.getenv('GPG_PASSPHRASE') }
    }
    // Do not sign archives by default (a local build without gpg keyring should succeed)
    if (taskGraph.allTasks.any { it.name == 'build' || it.name == 'assemble' }) {
        tasks.findAll { it.name == 'signArchives' || it.name == 'signDocsJar' || it.name == 'signTestJar' }.each { task ->
            task.enabled = false
        }
    }
}

signing
{
    sign configurations.archives
}
build.dependsOn.remove(signArchives)

/**
 * Runs Atlas Checks configured through the gradle.properties file. Multiple run profiles
 * may be defined through project properties. Set the profile project property to switch
 * between profiles.  Default is local.
 *
 * To change the profile, simply run "gradle -Pprofile=remote run"
 */
task runChecks(type: JavaExec, dependsOn: 'assemble', description: 'Executes the Atlas Check Spark job.') {
    classpath = sourceSets.main.runtimeClasspath

    main = project.property("checks.${project.profile}.mainClass")

    // apply arguments defined in the gradle.properties file for this profile
    def flags = project.properties.findAll { property ->
        property.toString().startsWith("checks.${project.profile}")
    } collect {
        it.toString().replace("checks.${project.profile}.", "-")
    } collect {
        it.toString().replace("@ROOTDIR@", rootDir.getAbsolutePath())
    } collect {
        it.toString().replace("@BUILDDIR@", buildDir.getAbsolutePath())
    }
    args(flags)

    // add log4j config to the classpath
    classpath('./config/log4j')

    // uncomment to change jvm args
    // jvmArgs(["-Xmx8g","-Xms8g"])

    // uncomment to enable jvm debugging
    // debug=true
}

/**
 * Wraps runChecks to perform any task involving setup or teardown
 */
task run(dependsOn: 'assemble', group: 'application', description: 'Runs the Atlas Check framework configured using profiles defined in gradle.properties.') {
    doLast {
        runChecks.getCommandLine().each {
            line -> println("$line \\")
        }
        runChecks.execute()
    }
}

task buildCheck(type: Copy) {
    if (project.hasProperty('CheckName')) {
        def checkName = project.property('CheckName')
        def username = System.properties["user.name"]
        println 'Building new check org.openstreetmap.atlas.checks.validation.' + checkName + '.java'
        // rename file and move to src directory
        from("gradle/template") {
            include 'checks.template'
            filter(org.apache.tools.ant.filters.ReplaceTokens, tokens: ['CHECKNAME' : checkName, 'USERNAME' : username])
            rename 'checks.template', checkName + '.java'
        }
        into 'src/main/java/org/openstreetmap/atlas/checks/validation'
        // update configuration and include new check
    }
}

task syncLibs(type: Sync) {
    into "libs"
    from configurations.runtime
}


// Rio addons
rio
{
    library
    { isPublic = true }
}

publish.dependsOn shaded
publish.dependsOn shadowJar

artifacts {
    archives shaded
    archives shadowJar
}

publishing.publications {
    rioLibrary(MavenPublication) {
        groupId project.group
        artifactId project.name
        artifact shaded {
            classifier "shaded"
        }
        artifact shadowJar {
            classifier "fat"
        }
    }
}
